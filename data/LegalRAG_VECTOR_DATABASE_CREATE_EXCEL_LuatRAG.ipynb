{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thực hiện lưu từng dòng trong cột \"Đáp án\" thành 1 chunk trong Qdrant mà không cần chia nhỏ nữa,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30364,
     "status": "ok",
     "timestamp": 1701544569753,
     "user": {
      "displayName": "phatjk",
      "userId": "06940104252696149723"
     },
     "user_tz": -420
    },
    "id": "bQ4HnUjc5WwI",
    "outputId": "422bb50e-05ad-4e47-819a-f71fae5e92c8"
   },
   "outputs": [],
   "source": [
    "### Import các thư viện cần thiết\n",
    "!pip install langchain qdrant-client -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "import pandas as pd\n",
    "\n",
    "# Define constants for Qdrant and Hugging Face API keys\n",
    "# QDRANT_API_KEY = \"WbQ_\"\n",
    "# QDRANT_URL = \"\"\n",
    "# EMBEDDINGS_MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "# HUGGINGFACE_API_KEY = \"hf_\" # Your Hugging Face API key\n",
    "# COLLECTION_NAME = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Excel data\n",
    "DATA = 'LegalRAG.xlsx'\n",
    "data = pd.read_excel(DATA)\n",
    "\n",
    "# Extract and preprocess the \"Đáp án\" column\n",
    "answers = data[\"Đáp án\"].dropna().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate embeddings using HuggingFaceInferenceAPIEmbeddings\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    model_name=EMBEDDINGS_MODEL_NAME,\n",
    "    api_key=HUGGINGFACE_API_KEY  # Correctly setting API key\n",
    ")\n",
    "\n",
    "# Create a vector database in Qdrant\n",
    "qdrant = Qdrant.from_texts(\n",
    "    texts=answers,  # Directly use each row as a chunk\n",
    "    embedding=embeddings,\n",
    "    url=QDRANT_URL,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=False,\n",
    ")\n",
    "\n",
    "# Verify if the data is added successfully\n",
    "print(f\"Number of chunks added: {len(answers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add thêm sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để thêm thông tin metadata như `\"source\"` vào mỗi chunk và định dạng như bạn yêu cầu, chúng ta sẽ làm như sau:\n",
    "\n",
    "1. **Thêm metadata:** Gắn thêm trường `source` chứa đường dẫn đến tệp dữ liệu gốc.\n",
    "2. **Sử dụng vòng lặp:** Lặp qua các chunk và in ra nội dung cùng metadata như bạn yêu cầu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "# from langchain.vectorstores import Qdrant\n",
    "# from langchain.schema import Document  # Import Document class\n",
    "# import pandas as pd\n",
    "\n",
    "# # # Define constants for Qdrant and Hugging Face API keys\n",
    "# QDRANT_API_KEY = \"WbQ_\"\n",
    "# QDRANT_URL = \"\"\n",
    "# EMBEDDINGS_MODEL_NAME = \"\"\n",
    "# HUGGINGFACE_API_KEY = \"hf_\" # Your Hugging Face API key\n",
    "# COLLECTION_NAME = \"\"\n",
    "\n",
    "# # File source for metadata\n",
    "# SOURCE_FILE = \"LegalRAG.xlsx\"\n",
    "\n",
    "# # Load Excel data\n",
    "# data = pd.read_excel(SOURCE_FILE)\n",
    "\n",
    "# # Extract and preprocess the \"Đáp án\" column\n",
    "# answers = data[\"Đáp án\"].dropna().tolist()\n",
    "\n",
    "# # Add metadata to each chunk and create Document objects\n",
    "# documents = [Document(page_content=answer, metadata={\"source\": SOURCE_FILE}) for answer in answers]\n",
    "\n",
    "# # Generate embeddings using HuggingFaceInferenceAPIEmbeddings\n",
    "# embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "#     model_name=EMBEDDINGS_MODEL_NAME,\n",
    "#     api_key=HUGGINGFACE_API_KEY\n",
    "# )\n",
    "\n",
    "# # Create a vector database in Qdrant\n",
    "# qdrant = Qdrant.from_documents(\n",
    "#     documents=documents,\n",
    "#     embedding=embeddings,\n",
    "#     url=QDRANT_URL,\n",
    "#     collection_name=COLLECTION_NAME,\n",
    "#     api_key=QDRANT_API_KEY,\n",
    "#     prefer_grpc=False,\n",
    "# )\n",
    "\n",
    "# # Verify if the data is added successfully and print chunks\n",
    "# for i, doc in enumerate(documents):\n",
    "#     print(f\"Document {i + 1} content: {doc.page_content[:100]}\")  # In 100 ký tự đầu tiên\n",
    "#     print(f\"Document {i + 1} metadata: {doc.metadata}\")\n",
    "#     if not doc.page_content.strip():\n",
    "#         print(f\"Document {i + 1} is empty!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "Mỗi chunk sẽ có thông tin sau:\n",
    "- **`content`**: Nội dung của chunk (các dòng từ cột \"Đáp án\").\n",
    "- **`metadata`**: Metadata bao gồm thông tin về nguồn dữ liệu (`source`).\n",
    "\n",
    "Ví dụ:\n",
    "```plaintext\n",
    "Document 1 content: Luật này quy định về quy tắc giao thông đường bộ; kết cấu hạ tầng giao thông đường bộ; phương tiện...\n",
    "Document 1 metadata: {'source': 'LegalRAG.xlsx'}\n",
    "```\n",
    "\n",
    "### Giải thích\n",
    "1. **`documents` array**: Chứa danh sách các đoạn văn bản với `page_content` và `metadata`.\n",
    "2. **Thêm metadata `source`**: Gắn thông tin nguồn tệp vào metadata của mỗi chunk.\n",
    "3. **In nội dung và metadata**: Kiểm tra từng chunk để đảm bảo dữ liệu đã được xử lý đúng cách.\n",
    "\n",
    "Hãy thử chạy và kiểm tra kết quả!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add thêm Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra hàng có \"Câu hỏi\" nhưng không có \"Đáp án\"\n",
    "questions_without_answers = data[data[\"Câu hỏi\"].notna() & data[\"Đáp án\"].isna()]\n",
    "\n",
    "# Kiểm tra hàng có \"Đáp án\" nhưng không có \"Câu hỏi\"\n",
    "answers_without_questions = data[data[\"Đáp án\"].notna() & data[\"Câu hỏi\"].isna()]\n",
    "\n",
    "# Hiển thị kết quả\n",
    "print(\"Rows with questions but no answers:\")\n",
    "print(questions_without_answers)\n",
    "\n",
    "print(\"\\nRows with answers but no questions:\")\n",
    "print(answers_without_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.schema import Document  # Import Document class\n",
    "import pandas as pd\n",
    "\n",
    "QDRANT_API_KEY = \"WbQ_\"\n",
    "QDRANT_URL = \"\"\n",
    "EMBEDDINGS_MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "HUGGINGFACE_API_KEY = \"hf_\" # Your Hugging Face API key\n",
    "COLLECTION_NAME = \"\"\n",
    "\n",
    "# File source for metadata\n",
    "SOURCE_FILE = \"LegalRAG.xlsx\"\n",
    "\n",
    "# Load Excel data\n",
    "data = pd.read_excel(SOURCE_FILE)\n",
    "\n",
    "# Extract and preprocess the \"Câu hỏi\" and \"Đáp án\" columns\n",
    "questions = data[\"Câu hỏi\"].dropna().tolist()\n",
    "answers = data[\"Đáp án\"].dropna().tolist()\n",
    "\n",
    "# Ensure questions and answers have the same length\n",
    "assert len(questions) == len(answers), \"Mismatch between number of questions and answers!\"\n",
    "\n",
    "# Add metadata to each chunk and create Document objects\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=answer,\n",
    "        metadata={\"source\": SOURCE_FILE, \"question\": question}\n",
    "    )\n",
    "    for question, answer in zip(questions, answers)\n",
    "]\n",
    "\n",
    "# Generate embeddings using HuggingFaceInferenceAPIEmbeddings\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    model_name=EMBEDDINGS_MODEL_NAME,\n",
    "    api_key=HUGGINGFACE_API_KEY\n",
    ")\n",
    "\n",
    "# Create a vector database in Qdrant\n",
    "qdrant = Qdrant.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    url=QDRANT_URL,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=False,\n",
    ")\n",
    "\n",
    "# Verify if the data is added successfully and print chunks\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Document {i + 1} content: {doc.page_content[:100]}\")  # In 100 ký tự đầu tiên\n",
    "    print(f\"Document {i + 1} metadata: {doc.metadata}\")\n",
    "    if not doc.page_content.strip():\n",
    "        print(f\"Document {i + 1} is empty!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Thay đổi chính\n",
    "1. **Thêm metadata `question`:** Thêm trường `question` vào metadata cho mỗi chunk.\n",
    "2. **Kiểm tra độ dài danh sách:** Đảm bảo rằng số lượng câu hỏi và câu trả lời khớp nhau để tránh lỗi khi tạo `Document`.\n",
    "3. **Metadata đầy đủ:** Mỗi `Document` giờ sẽ có cả trường `source` và `question`.\n",
    "\n",
    "### Output\n",
    "Mỗi tài liệu sẽ có metadata như:\n",
    "```plaintext\n",
    "Document 1 content: Luật này quy định về quy tắc giao thông đường bộ...\n",
    "Document 1 metadata: {'source': 'LegalRAG.xlsx', 'question': 'Trình bày khái niệm, chế độ pháp lý vùng nội thủy...'}\n",
    "``` \n",
    "\n",
    "Hãy thử và kiểm tra kết quả! 😊"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMo/4/eme+yWt+NjHLhRca0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
